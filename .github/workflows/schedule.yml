name: Run Streamlit Job Weekly
on:
  schedule:
    - cron: '0 6 * * 1'  # Runs weekly on Monday at 6 AM UTC
  workflow_dispatch:  # Allows manual triggering

jobs:
  run-script:
    runs-on: ubuntu-latest
    timeout-minutes: 250  # Increased from 30 to 60 minutes
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        timeout-minutes: 5  # Fails if checkout takes >5 minutes

      - name: Set up Python
        uses: actions/setup-python@v5
        timeout-minutes: 5  # Fails if setup takes >5 minutes
        with:
          python-version: '3.9'

      - name: Install dependencies
        timeout-minutes: 5  # Fails if install takes >5 minutes
        run: |
          echo "ðŸ“¦ Installing dependencies..."
          pip install -r requirements.txt
          pip install gspread oauth2client pandas  # Ensure pandas is installed

      - name: Debug Environment Variables
        run: |
          echo "ðŸ” Debugging Environment Variables..."
          echo "GOOGLE_SHEETS_CREDS length: $(echo -n '${{ secrets.GOOGLE_SHEETS_CREDS }}' | wc -c)"
          echo "SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}"
          echo "SERP_API_KEY length: $(echo -n '${{ secrets.SERP_API_KEY }}' | wc -c)"

      - name: Get all campaign names from Google Sheets
        id: get_campaigns
        env:
          GOOGLE_SHEETS_CREDS: ${{ secrets.GOOGLE_SHEETS_CREDS }}
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
        run: |
          echo "ðŸ” Fetching campaign names from Google Sheets..."
          python -c "
          import gspread
          from oauth2client.service_account import ServiceAccountCredentials
          import json
          import os
          import sys
          try:
              creds_raw = os.getenv('GOOGLE_SHEETS_CREDS')
              if not creds_raw:
                  raise ValueError('GOOGLE_SHEETS_CREDS is not set or empty')
              print(f'GOOGLE_SHEETS_CREDS length: {len(creds_raw)}')
              print(f'GOOGLE_SHEETS_CREDS preview: {creds_raw[:50]}...')
              creds_dict = json.loads(creds_raw)
              if isinstance(creds_dict, str):
                  print('Detected double-encoded creds, parsing again...')
                  creds_dict = json.loads(creds_dict)
              print(f'Parsed GOOGLE_SHEETS_CREDS with keys: {list(creds_dict.keys())}')
              scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
              creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
              client = gspread.authorize(creds)
              spreadsheet = client.open_by_key(os.getenv('SPREADSHEET_ID'))
              sheet = spreadsheet.worksheet('campaigns')
              campaigns = [row['campaign_name'] for row in sheet.get_all_records()]
              with open('campaigns.txt', 'w') as f:
                  f.write(','.join(campaigns))
              print(f'Found {len(campaigns)} campaigns: {campaigns}')
          except Exception as e:
              print(f'Error fetching campaigns: {str(e)}', file=sys.stderr)
              sys.exit(1)
          "
          echo "campaigns=$(cat campaigns.txt)" >> $GITHUB_OUTPUT

      - name: Run the script for each campaign
        env:
          GOOGLE_SHEETS_CREDS: ${{ secrets.GOOGLE_SHEETS_CREDS }}
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
          SERP_API_KEY: ${{ secrets.SERP_API_KEY }}
        timeout-minutes: 300  # Increased from 25 to 55 minutes
        run: |
          echo "ðŸš€ Running app.py for all campaigns..."
          IFS=',' read -r -a campaigns <<< "${{ steps.get_campaigns.outputs.campaigns }}"
          for campaign in "${campaigns[@]}"; do
            if [ -n "$campaign" ] && [ "$campaign" != "Total" ]; then  # Skip "Total" as it's not a real campaign
              echo "Processing campaign: $campaign"
              python app.py github "$campaign" || echo "âš ï¸ Failed to process $campaign"
              sleep 5  # Small delay to avoid overwhelming APIs
              echo "âœ… Script execution completed for campaign $campaign"
            fi
          done
          echo "Computing Total data..."
          python -c "from app import compute_and_store_total_data; compute_and_store_total_data()"

      - name: Capture Logs
        if: always()  # Runs even if previous steps fail
        run: |
          echo "ðŸ“œ Capturing logs..."
          cat logs.txt || echo "âš ï¸ No logs.txt found."

      - name: Upload logs as artifact
        if: always()  # Uploads logs even on failure
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: logs.txt
